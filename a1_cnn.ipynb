{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4186 Assignment 1: CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahil\\anaconda3\\envs\\cv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from utils import query_crop, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similarity(query_feat, gallery_feat):\n",
    "#     sim = cosine_similarity(query_feat, gallery_feat)\n",
    "#     sim = np.squeeze(sim)\n",
    "#     return sim\n",
    "\n",
    "def resnet_extraction(img, featsave_path):\n",
    "    resnet_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])\n",
    "    img_transform = resnet_transform(img).to(device) #normalize the input image and transform it to tensor.\n",
    "    \n",
    "    img_transform = torch.unsqueeze(img_transform, 0) #Set batchsize as 1. You can enlarge the batchsize to accelerate.\n",
    "    \n",
    "    feats = cnn_model(img_transform) # extract feature\n",
    "    feats_np = feats.cpu().detach().numpy() # convert tensor to numpy\n",
    "    np.save(featsave_path, feats_np, allow_pickle=True) # save the featur\n",
    "\n",
    "def feat_extractor_gallery(gallery_dir, feat_savedir):\n",
    "    for img_file in tqdm(os.listdir(gallery_dir)):\n",
    "        img = cv2.imread(os.path.join(gallery_dir, img_file))\n",
    "        img = img[:,:,::-1] #bgr2rgb\n",
    "        img_resize = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC) # resize the image\n",
    "        featsave_path = os.path.join(feat_savedir, img_file.split('.')[0]+'.npy')\n",
    "        resnet_extraction(img_resize, featsave_path)\n",
    "\n",
    "# Extract the query feature\n",
    "def feat_extractor_query():\n",
    "    query_dir = './datasets_4186/query_4186/'\n",
    "    txt_dir = './datasets_4186/query_txt_4186/'\n",
    "    save_dir =  './datasets_4186/query_cropped/'\n",
    "    featsave_dir = './datasets_4186/query_feature/'\n",
    "    for query_file in tqdm(os.listdir(query_dir)):\n",
    "        if query_file.endswith(\".DS_Store\"):\n",
    "            continue\n",
    "        print(query_file)\n",
    "        img_name = query_file[0:query_file.find('.')]\n",
    "        txt_file = img_name+'.txt'\n",
    "        featsave_file = img_name+'_feats.npy'\n",
    "        query_path = os.path.join(query_dir, query_file)\n",
    "        txt_path = os.path.join(txt_dir, txt_file)\n",
    "        save_path = os.path.join(save_dir, query_file)\n",
    "        featsave_path =os.path.join(featsave_dir, featsave_file) \n",
    "        crop = query_crop(query_path, txt_path, save_path)\n",
    "        crop_resize = cv2.resize(crop, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        resnet_extraction(crop_resize, featsave_path)\n",
    "\n",
    "def retrival_idx(query_path, gallery_dir):\n",
    "    query_feat = np.load(query_path, allow_pickle=True)\n",
    "    # print(query_feat)\n",
    "    \n",
    "    dict_values = {}\n",
    "    # print(dict_values)\n",
    "    \n",
    "    for gallery_file in os.listdir(gallery_dir):\n",
    "        gallery_feat = np.load(os.path.join(gallery_dir, gallery_file),  allow_pickle=True)\n",
    "        gallery_idx = gallery_file.split('.')[0] + '.jpg'\n",
    "        sim = similarity(query_feat, gallery_feat)\n",
    "        # print(sim)\n",
    "        dict_values[gallery_idx] = sim\n",
    "    sorted_dict = sorted(dict_values.items(), key=lambda item: item[1]) # Sort the similarity score\n",
    "    best_ten = sorted_dict[-10:] # Get the best five retrived images\n",
    "    # print(best_ten)\n",
    "    return best_ten\n",
    "\n",
    "# def retrival_idx(query_path, gallery_dir):\n",
    "#     query_feat = np.load(query_path, allow_pickle=True)\n",
    "#     print(query_feat)\n",
    "    \n",
    "#     dict_values = {}\n",
    "#     print(dict_values)\n",
    "    \n",
    "#     for gallery_file in os.listdir(gallery_dir):\n",
    "#         gallery_feat = np.load(os.path.join(gallery_dir, gallery_file),  allow_pickle=True)\n",
    "#         gallery_idx = gallery_file.split('.')[0] + '.jpg'\n",
    "#         sim = cosine_similarity(query_feat, gallery_feat)\n",
    "#         print(sim)\n",
    "#         dict_values[gallery_idx] = sim\n",
    "#     sorted_dict = sorted(dict_values.items(), key=lambda item: item[1]) # Sort the similarity score\n",
    "#     best_ten = sorted_dict[-10:] # Get the best five retrived images\n",
    "#     print(best_ten)\n",
    "#     return best_ten\n",
    "\n",
    "def visulization(retrived, query):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.title('query')\n",
    "    query_img = cv2.imread(query)\n",
    "    img_rgb_rgb = query_img[:,:,::-1]\n",
    "    plt.imshow(img_rgb_rgb)\n",
    "    for i in range(5):\n",
    "        img_path = './data/gallery/' + retrived[i][0]\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = img[:,:,::-1]\n",
    "        plt.subplot(2, 3, i+2)\n",
    "        plt.title(retrived[i][1])\n",
    "        plt.imshow(img_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available()==True else 'cpu'\n",
    "\n",
    "# cnn_model = models.vgg16(pretrained=True)\n",
    "# modules=list(cnn_model.children())[:-1]\n",
    "# cnn_model=nn.Sequential(*modules)\n",
    "# for p in cnn_model.parameters():\n",
    "#     p.requires_grad = False\n",
    "\n",
    "# cnn_model = cnn_model.to(device)\n",
    "\n",
    "cnn_model = models.vgg16(pretrained=True).to(device)\n",
    "cnn_model_features = cnn_model.features\n",
    "cnn_model_features.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responsible for Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▋                                                           | 6/21 [00:02<00:04,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656.jpg\n",
      "1709.jpg\n",
      "2032.jpg\n",
      "2040.jpg\n",
      "2176.jpg\n",
      "2461.jpg\n",
      "27.jpg\n",
      "2714.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████▌                       | 15/21 [00:02<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.jpg\n",
      "35.jpg\n",
      "3502.jpg\n",
      "3557.jpg\n",
      "3833.jpg\n",
      "3906.jpg\n",
      "4354.jpg\n",
      "4445.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4716.jpg\n",
      "4929.jpg\n",
      "776.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [02:02<00:00, 40.78it/s]\n"
     ]
    }
   ],
   "source": [
    "feat_extractor_query()\n",
    "\n",
    "gallery_dir = './datasets_4186/gallery_4186/'\n",
    "feat_savedir = './datasets_4186/gallery_feature/'\n",
    "\n",
    "feat_extractor_gallery(gallery_dir, feat_savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets_4186/query_feature/1258_feats.npy\n",
      "./datasets_4186/query_feature/1656_feats.npy\n",
      "./datasets_4186/query_feature/1709_feats.npy\n",
      "./datasets_4186/query_feature/2032_feats.npy\n",
      "./datasets_4186/query_feature/2040_feats.npy\n",
      "./datasets_4186/query_feature/2176_feats.npy\n",
      "./datasets_4186/query_feature/2461_feats.npy\n",
      "./datasets_4186/query_feature/2714_feats.npy\n",
      "./datasets_4186/query_feature/27_feats.npy\n",
      "./datasets_4186/query_feature/316_feats.npy\n",
      "./datasets_4186/query_feature/3502_feats.npy\n",
      "./datasets_4186/query_feature/3557_feats.npy\n",
      "./datasets_4186/query_feature/35_feats.npy\n",
      "./datasets_4186/query_feature/3833_feats.npy\n",
      "./datasets_4186/query_feature/3906_feats.npy\n",
      "./datasets_4186/query_feature/4354_feats.npy\n",
      "./datasets_4186/query_feature/4445_feats.npy\n",
      "./datasets_4186/query_feature/4716_feats.npy\n",
      "./datasets_4186/query_feature/4929_feats.npy\n",
      "./datasets_4186/query_feature/776_feats.npy\n"
     ]
    }
   ],
   "source": [
    "queryf_dir = './datasets_4186/query_feature/'\n",
    "gallery_dir = './datasets_4186/gallery_feature/'\n",
    "query_dir = './datasets_4186/query_4186/'\n",
    "\n",
    "for queryf_file in os.listdir(queryf_dir):\n",
    "    print(os.path.join(queryf_dir, queryf_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2962.jpg 0.68862295\n",
      "4700.jpg 0.6902053\n",
      "848.jpg 0.69110155\n",
      "3141.jpg 0.6996869\n",
      "4154.jpg 0.70124394\n",
      "3689.jpg 0.70166326\n",
      "2941.jpg 0.7066506\n",
      "4937.jpg 0.70798695\n",
      "2368.jpg 0.7145618\n",
      "2403.jpg 0.77600527\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i[\u001b[38;5;241m0\u001b[39m], i[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     15\u001b[0m best_ten\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m---> 16\u001b[0m \u001b[43mvisulization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_ten\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueryf_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mvisulization\u001b[1;34m(retrived, query)\u001b[0m\n\u001b[0;32m     86\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m query_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(query)\n\u001b[1;32m---> 88\u001b[0m img_rgb_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mquery_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     89\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img_rgb_rgb)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "queryf_dir = './datasets_4186/query_feature/'\n",
    "gallery_dir = './datasets_4186/gallery_feature/'\n",
    "query_dir = './datasets_4186/query_4186/'\n",
    "\n",
    "for queryf_file in os.listdir(queryf_dir):\n",
    "    # print(\"Reached here 1 {}\".format(queryf_file))\n",
    "    # print(queryf_file + \"\\n Best ten:\")\n",
    "    # print(os.path.join(queryf_dir, queryf_file))\n",
    "    # print(\"Reached here 2\")\n",
    "    best_ten = retrival_idx(os.path.join(queryf_dir, queryf_file), gallery_dir) # retrieve top 10 matching images in the gallery.\n",
    "    # print(\"Reached here 3\")\n",
    "    \n",
    "    for i in best_ten:\n",
    "        print(i[0], i[1])\n",
    "    best_ten.reverse()\n",
    "    visulization(best_ten, queryf_file.split('_')[0]+'.jpg') # Visualize the retrieval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "297dae0d96d0fe8242f706e5f11dc7776c1210d6b0a97abea12f778fdecf7be1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
