{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_crop(query_path, txt_path, save_path):\n",
    "    query_img = cv2.imread(query_path)\n",
    "    query_img = query_img[:,:,::-1] #bgr2rgb\n",
    "    txt = np.loadtxt(txt_path)     #load the coordinates of the bounding box\n",
    "    crop = query_img[int(txt[1]):int(txt[1] + txt[3]), int(txt[0]):int(txt[0] + txt[2]), :] #crop the instance region\n",
    "    cv2.imwrite(save_path, crop[:,:,::-1])  #save the cropped region\n",
    "    return crop\n",
    "\n",
    "def vgg_11_extraction(img, featsave_path):\n",
    "    resnet_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])\n",
    "    img_transform = resnet_transform(img) #normalize the input image and transform it to tensor.\n",
    "    img_transform = torch.unsqueeze(img_transform, 0) #Set batchsize as 1. You can enlarge the batchsize to accelerate.\n",
    "\n",
    "    # initialize the weights pretrained on the ImageNet dataset, you can also use other backbones (e.g. ResNet, XceptionNet, AlexNet, ...)\n",
    "    # and extract features from more than one layer.\n",
    "    vgg11 = models.vgg11(pretrained=True)\n",
    "    vgg11_feat_extractor = vgg11.features #define the feature extractor\n",
    "    vgg11_feat_extractor.eval()  #set the mode as evaluation\n",
    "    feats = vgg11(img_transform) # extract feature\n",
    "    feats_np = feats.cpu().detach().numpy() # convert tensor to numpy\n",
    "    np.save(featsave_path, feats_np) # save the feature\n",
    "\n",
    "# Note that I feed the whole image into the pretrained vgg11 model to extract the feature, which will lead to a poor retrieval performance.\n",
    "# To extract more fine-grained features, you could preprocess the gallery images by cropping them using windows with different sizes and shapes.\n",
    "# Hint: opencv provides some off-the-shelf tools for image segmentation.\n",
    "def feat_extractor_gallery(gallery_dir, feat_savedir):\n",
    "    for img_file in tqdm(os.listdir(gallery_dir)):\n",
    "        img = cv2.imread(os.path.join(gallery_dir, img_file))\n",
    "        img = img[:,:,::-1] #bgr2rgb\n",
    "        img_resize = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC) # resize the image\n",
    "        featsave_path = os.path.join(feat_savedir, img_file.split('.')[0]+'.npy')\n",
    "        vgg_11_extraction(img_resize, featsave_path)\n",
    "\n",
    "# Extract the query feature\n",
    "def feat_extractor_query():\n",
    "    query_path = './data/query/query.jpg'\n",
    "    txt_path = './data/query_txt/query.txt'\n",
    "    save_path = './data/cropped_query/query.jpg'\n",
    "    featsave_path = './data/query_feat/query_feats.npy'\n",
    "    crop = query_crop(query_path, txt_path, save_path)\n",
    "    crop_resize = cv2.resize(crop, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    vgg_11_extraction(crop_resize, featsave_path)\n",
    "\n",
    "def main():\n",
    "    feat_extractor_query()\n",
    "    gallery_dir = './data/gallery/'\n",
    "    feat_savedir = './data/gallery_feature/'\n",
    "    feat_extractor_gallery(gallery_dir, feat_savedir)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
